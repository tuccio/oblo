#version 460

#extension GL_GOOGLE_include_directive : require
#extension GL_EXT_control_flow_attributes : enable
#extension GL_EXT_buffer_reference : require
#extension GL_EXT_samplerless_texture_functions : require
#extension GL_EXT_shader_8bit_storage : require
#extension GL_ARB_gpu_shader_int64 : require

#include <renderer/camera>
#include <renderer/instances>
#include <renderer/math>
#include <renderer/meshes/mesh_attributes>
#include <renderer/meshes/mesh_data>
#include <renderer/meshes/mesh_indices>
#include <renderer/meshes/mesh_table>
#include <renderer/motion_vectors>
#include <renderer/transform>
#include <visibility/visibility_buffer>
#include <visibility/visibility_utils>

#ifdef OUT_MOTION_VECTORS
layout(binding = 0, OBLO_MOTION_VECTORS_FORMAT) uniform restrict writeonly image2D t_OutMotionVectors;
#endif

#ifdef OUT_DISOCCLUSION_MASK
layout(binding = 1, r8) uniform restrict writeonly image2D t_OutDisocclusionMask;
#endif

#if defined(OUT_MOTION_VECTORS) || defined(OUT_DISOCCLUSION_MASK)
layout(binding = 5) uniform texture2D t_InLastFrameDepth;
#endif

layout(binding = 6, rg32ui) uniform restrict readonly uimage2D t_InVisibilityBuffer;

layout(binding = 16) uniform b_CameraBuffer
{
    camera_buffer g_Camera;
};

const uint g_ThreadLocalSize = 8;

layout(local_size_x = g_ThreadLocalSize, local_size_y = g_ThreadLocalSize, local_size_z = 1) in;

struct extra_buffers_output
{
#if defined(OUT_MOTION_VECTORS) || defined(OUT_DISOCCLUSION_MASK)
    vec2 motionVectors;
#endif

#ifdef OUT_DISOCCLUSION_MASK
    float disocclusion;
#endif
};

extra_buffers_output calculate_outputs(in visibility_buffer_data vb, in ivec2 coords, in uvec2 resolution)
{
    extra_buffers_output r;

    const mesh_handle mesh = OBLO_INSTANCE_DATA(vb.instanceTableId, i_MeshHandles, vb.instanceId);
    const transform transform = OBLO_INSTANCE_DATA(vb.instanceTableId, i_TransformBuffer, vb.instanceId);

    // Read the mesh data
    const mesh_table meshTable = mesh_table_fetch(mesh);

    const uvec3 vertexIndices = mesh_get_meshlet_indices(meshTable, mesh, vb.meshletId, vb.meshletTriangleId);

    triangle triangleWS;

#if defined(OUT_MOTION_VECTORS) || defined(OUT_DISOCCLUSION_MASK)
    triangle prevTriangleWS;
#endif

    // Read the vertex data and transform everything in world space, we do lighting calculation in that
    // space
    [[unroll]] for (uint i = 0; i < 3; ++i)
    {
        const uint vertexId = vertexIndices[i];

        const vec4 vertexPosition = vec4(mesh_get_position(meshTable, vertexId), 1);

        triangleWS.v[i] = (transform.localToWorld * vertexPosition).xyz;

#if defined(OUT_MOTION_VECTORS) || defined(OUT_DISOCCLUSION_MASK)
        prevTriangleWS.v[i] = (transform.lastFrameLocalToWorld * vertexPosition).xyz;
#endif
    }

    const vec2 ndc = screen_to_ndc(uvec2(coords), resolution);

    const ray cameraRay = visibility_calculate_camera_ray(g_Camera, ndc);

    float intersectionDistance;

    distance_from_triangle_plane(cameraRay, triangleWS, intersectionDistance);

    const vec3 positionWS = ray_point_at(cameraRay, intersectionDistance);

    barycentric_coords bc;
    barycentric_calculate(bc, triangleWS.v, positionWS);

#if defined(OUT_MOTION_VECTORS) || defined(OUT_DISOCCLUSION_MASK)
    const vec3 prevPositionWS = barycentric_interpolate(bc, prevTriangleWS.v);
    const vec2 prevNDC = visibility_calculate_position_ndc_2d(g_Camera.lastFrameViewProjection, prevPositionWS);

    r.motionVectors = ndc - prevNDC.xy;
#endif

#ifdef OUT_DISOCCLUSION_MASK
    // Reproject using motion vectors
    // Calculate expected old depth
    // Sample actual old depth at the pixel
    // If the expected old depth is less (reverse Z) than the sampled depth, we assume disocclusion

    const ivec2 pixelOffset = ivec2(resolution * r.motionVectors + vec2(.5f));
    const ivec2 oldCoords = coords - pixelOffset;

    if (oldCoords.x < 0 || oldCoords.y < 0 || oldCoords.x >= resolution.x || oldCoords.y >= resolution.y)
    {
        r.disocclusion = 1;
    }
    else
    {
        const float oldSampledDepth = texelFetch(t_InLastFrameDepth, oldCoords, 0).x;

        const float oldLinearDepth = camera_linearize_depth_ndc(g_Camera, oldSampledDepth);
        const float currentLinearDepth = -(g_Camera.view * vec4(positionWS, 1)).z;

        const float g_DisocclusionTolerance = 3e0f;
        const bool isDisoccluded = oldLinearDepth > currentLinearDepth + g_DisocclusionTolerance;

        r.disocclusion = isDisoccluded ? 1.f : 0.f;
    }
#endif

    return r;
}

void main()
{
    const uvec2 resolution = imageSize(t_InVisibilityBuffer);
    const uvec2 screenPos = gl_GlobalInvocationID.xy;

    if (screenPos.x >= resolution.x || screenPos.y >= resolution.y)
    {
        return;
    }

    const uvec4 vbPixel = imageLoad(t_InVisibilityBuffer, ivec2(screenPos));

    extra_buffers_output r;

    visibility_buffer_data vb;

    if (visibility_buffer_parse(vbPixel.xy, vb))
    {
        r = calculate_outputs(vb, ivec2(screenPos), resolution);
    }
    else
    {
#ifdef OUT_MOTION_VECTORS
        r.motionVectors = vec2(0);
#endif

#ifdef OUT_DISOCCLUSION_MASK
        r.disocclusion = 1;
#endif
    }

#ifdef OUT_MOTION_VECTORS
    const vec2 motionVectors = motion_vectors_encode(r.motionVectors);
    imageStore(t_OutMotionVectors, ivec2(screenPos), vec4(motionVectors, 0, 0));
#endif

#ifdef OUT_DISOCCLUSION_MASK
    imageStore(t_OutDisocclusionMask, ivec2(screenPos), vec4(r.disocclusion, 0, 0, 0));
#endif
}