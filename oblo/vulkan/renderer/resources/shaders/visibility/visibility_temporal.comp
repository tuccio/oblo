#version 460

#extension GL_GOOGLE_include_directive : require
#extension GL_EXT_control_flow_attributes : enable
#extension GL_EXT_buffer_reference : require
#extension GL_EXT_samplerless_texture_functions : require
#extension GL_EXT_shader_8bit_storage : require
#extension GL_ARB_gpu_shader_int64 : require

#include <renderer/camera>
#include <renderer/instances>
#include <renderer/math>
#include <renderer/meshes/mesh_attributes>
#include <renderer/meshes/mesh_data>
#include <renderer/meshes/mesh_indices>
#include <renderer/meshes/mesh_table>
#include <renderer/transform>
#include <visibility/visibility_buffer>
#include <visibility/visibility_utils>

layout(binding = 0, rg8) uniform restrict writeonly image2D t_OutMotionVectors;
layout(binding = 1, r8) uniform restrict writeonly image2D t_OutDisocclusionMask;

layout(binding = 4) uniform texture2D t_InCurrentDepth;
layout(binding = 5) uniform texture2D t_InLastFrameDepth;
layout(binding = 6, rg32ui) uniform restrict readonly uimage2D t_InVisibilityBuffer;

layout(binding = 16) uniform b_CameraBuffer
{
    camera_buffer g_Camera;
};

const uint g_ThreadLocalSize = 8;

layout(local_size_x = g_ThreadLocalSize, local_size_y = g_ThreadLocalSize, local_size_z = 1) in;

struct temporal_output
{
    vec2 motionVectors;
    float disocclusion;
};

temporal_output calculate_outputs(in visibility_buffer_data vb, in ivec2 coords, in uvec2 resolution)
{
    const mesh_handle mesh = OBLO_INSTANCE_DATA(vb.instanceTableId, i_MeshHandles, vb.instanceId);
    const transform transform = OBLO_INSTANCE_DATA(vb.instanceTableId, i_TransformBuffer, vb.instanceId);

    // Read the mesh data
    const mesh_table meshTable = mesh_table_fetch(mesh);

    const uvec3 vertexIndices = mesh_get_meshlet_indices(meshTable, mesh, vb.meshletId, vb.meshletTriangleId);

    triangle triangleWS;
    triangle prevTriangleWS;

    // Read the vertex data and transform everything in world space, we do lighting calculation in that
    // space
    [[unroll]] for (uint i = 0; i < 3; ++i)
    {
        const uint vertexId = vertexIndices[i];

        const vec4 vertexPosition = vec4(mesh_get_position(meshTable, vertexId), 1);

        triangleWS.v[i] = (transform.localToWorld * vertexPosition).xyz;
        prevTriangleWS.v[i] = (transform.lastFrameLocalToWorld * vertexPosition).xyz;
    }

    const vec2 ndc = screen_to_ndc(uvec2(coords), resolution);

    const ray cameraRay = visibility_calculate_camera_ray(g_Camera, ndc);

    float intersectionDistance;

    distance_from_triangle_plane(cameraRay, triangleWS, intersectionDistance);

    const vec3 positionWS = ray_point_at(cameraRay, intersectionDistance);

    barycentric_coords bc;
    barycentric_calculate(bc, triangleWS.v, positionWS);

    const vec3 prevPositionWS = barycentric_interpolate(bc, prevTriangleWS.v);

    const vec2 prevNDC =
        visibility_calculate_last_frame_position_ndc_2d(g_Camera.lastFrameViewProjection, prevPositionWS);

    // const vec2 prevNDC =
    //     visibility_calculate_last_frame_position_ndc_2d(ndc, g_Camera.lastFrameViewProjection, bc, prevTriangleWS);

    temporal_output r;
    r.motionVectors = prevNDC.xy - ndc;
    r.disocclusion = 0; // TODO

    // Reproject using motion vectors
    // Calculate expected old depth
    // Sample actual old depth at the pixel
    // If the expected old depth is less (reverse Z) than the sampled depth, we assume disocclusion

    const ivec2 pixelOffset = ivec2(resolution * (prevNDC.xy - ndc));
    const ivec2 oldCoords = coords + pixelOffset;

    if (oldCoords.x < 0 || oldCoords.y < 0 || oldCoords.x >= resolution.x || oldCoords.y >= resolution.y)
    {
        r.disocclusion = 1;
    }
    else
    {
        const float oldSampledDepth = texelFetch(t_InLastFrameDepth, oldCoords, 0).x;

        // TODO: This is wrong
        const float oldExpectedDepth = texelFetch(t_InCurrentDepth, coords, 0).x;
        // const float oldExpectedDepth = prevNDC.z;

        const float g_DisocclusionTolerance = 1e-3f;
        const bool isDisoccluded = oldSampledDepth > oldExpectedDepth + g_DisocclusionTolerance;

        // r.disocclusion = camera_linearize_depth_ndc(g_Camera, oldSampledDepth);
        r.disocclusion = isDisoccluded ? 1.f : 0.f;
    }

    return r;
}

void main()
{
    const uvec2 resolution = imageSize(t_InVisibilityBuffer);
    const uvec2 screenPos = gl_GlobalInvocationID.xy;

    if (screenPos.x >= resolution.x || screenPos.y >= resolution.y)
    {
        return;
    }

    const uvec4 vbPixel = imageLoad(t_InVisibilityBuffer, ivec2(screenPos));

    temporal_output r;

    visibility_buffer_data vb;

    if (visibility_buffer_parse(vbPixel.xy, vb))
    {
        r = calculate_outputs(vb, ivec2(screenPos), resolution);
    }
    else
    {
        r.motionVectors = vec2(0);
        r.disocclusion = 1;
    }

    imageStore(t_OutMotionVectors, ivec2(screenPos), vec4(r.motionVectors, 0, 0));
    imageStore(t_OutDisocclusionMask, ivec2(screenPos), vec4(r.disocclusion, 0, 0, 0));
}