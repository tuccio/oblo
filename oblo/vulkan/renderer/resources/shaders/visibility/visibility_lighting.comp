#version 460

#extension GL_ARB_gpu_shader_int64 : require
#extension GL_EXT_buffer_reference : require
#extension GL_EXT_nonuniform_qualifier : require
#extension GL_EXT_shader_16bit_storage : require
#extension GL_EXT_samplerless_texture_functions : require
#extension GL_GOOGLE_include_directive : require
#extension GL_KHR_shader_subgroup_quad : require

#include <renderer/barycentric>
#include <renderer/camera>
#include <renderer/instances>
#include <renderer/lights>
#include <renderer/material>
#include <renderer/math>
#include <renderer/meshes>
#include <renderer/raytrace>
#include <renderer/textures>
#include <renderer/transform>
#include <renderer/volumes>
#include <visibility/visibility_buffer>

layout(local_size_x = 64, local_size_y = 1, local_size_z = 1) in;

layout(binding = 0) uniform b_CameraBuffer
{
    camera_buffer g_Camera;
};

layout(binding = 1) uniform b_LightConfig
{
    light_config g_LightConfig;
};

layout(std430, binding = 2) restrict readonly buffer b_LightData
{
    light_data lights[];
};

layout(binding = 11, rg32ui) uniform restrict readonly uimage2D t_InVisibilityBuffer;

layout(binding = 12, rgba8) uniform restrict writeonly image2D t_OutLitImage;

layout(push_constant) uniform c_PushConstants
{
    uvec2 resolution;
}
g_Constants;

// Source:
// https://github.com/GPUOpen-Effects/FidelityFX-Denoiser/blob/master/ffx-shadows-dnsr/ffx_denoiser_shadows_util.h
//  LANE TO 8x8 MAPPING
//  ===================
//  00 01 08 09 10 11 18 19
//  02 03 0a 0b 12 13 1a 1b
//  04 05 0c 0d 14 15 1c 1d
//  06 07 0e 0f 16 17 1e 1f
//  20 21 28 29 30 31 38 39
//  22 23 2a 2b 32 33 3a 3b
//  24 25 2c 2d 34 35 3c 3d
//  26 27 2e 2f 36 37 3e 3f
uint bitfield_extract(uint src, uint off, uint bits)
{
    uint mask = (1u << bits) - 1;
    return (src >> off) & mask;
} // ABfe

uint bitfield_insert(uint src, uint ins, uint bits)
{
    uint mask = (1u << bits) - 1;
    return (ins & mask) | (src & (~mask));
} // ABfiM

uvec2 remap_lane_8x8(uint lane)
{
    return uvec2(bitfield_insert(bitfield_extract(lane, 2u, 3u), lane, 1u),
        bitfield_insert(bitfield_extract(lane, 3u, 3u), bitfield_extract(lane, 1u, 2u), 2u));
}

void main()
{
    const uvec2 localGroupId = remap_lane_8x8(gl_LocalInvocationIndex);
    const ivec2 screenPos = ivec2(gl_WorkGroupID.xy * 8 + localGroupId);

    if (screenPos.x >= g_Constants.resolution.x || screenPos.y >= g_Constants.resolution.y)
    {
        return;
    }

    // Parse the visibility buffer to find which triangle we are processing
    const uvec4 visBufferData = imageLoad(t_InVisibilityBuffer, screenPos);

    visibility_buffer_data vb;

    if (!visibility_buffer_parse(visBufferData.xy, vb))
    {
        // This means we didn't hit anything, and have no triangle in this pixel
        imageStore(t_OutLitImage, screenPos, vec4(0));
        return;
    }

    // Read the instance data we need
    const mesh_handle mesh = OBLO_INSTANCE_DATA(vb.instanceTableId, i_MeshHandles, vb.instanceId);
    const transform transform = OBLO_INSTANCE_DATA(vb.instanceTableId, i_TransformBuffer, vb.instanceId);
    const gpu_material material = OBLO_INSTANCE_DATA(vb.instanceTableId, i_MaterialBuffer, vb.instanceId);

    triangle triangleWS;
    vec2 triangleUV0[3];
    vec3 triangleNormalWS[3];

    uint vertexIndices[3];

    // Read the mesh data
    const mesh_table meshTable = mesh_table_fetch(mesh);
    mesh_get_vertex_indices(meshTable, vb.triangleIndex, vertexIndices);

    // Read the vertex data and transform everything in world space, we do lighting calculation in that space
    for (uint i = 0; i < 3; ++i)
    {
        const uint vertexId = vertexIndices[i];

        const vec3 vertexPosition = mesh_get_position(meshTable, vertexId);
        triangleWS.v[i] = (transform.localToWorld * vec4(vertexPosition, 1)).xyz;

        const vec3 vertexNormal = mesh_get_normal(meshTable, vertexId);
        triangleNormalWS[i] = (mat3(transform.normalMatrix) * vertexNormal);

        triangleUV0[i] = mesh_get_uv0(meshTable, vertexId);
    }

    // Cast a ray from the camera to the near plane and calculate the distance of the ray hit to the plane on the
    // triangle in world space, we use that to derive the position in world space
    const vec2 positionNDC = vec2(2 * screenPos) / g_Constants.resolution - 1.f;
    const vec3 screenPosWS = camera_unproject_world_space(g_Camera, positionNDC, 0);

    ray cameraRay;
    cameraRay.origin = g_Camera.position;
    cameraRay.direction = normalize(screenPosWS - g_Camera.position);

    float intersectionDistance;

    // Really the plan should be hitting here, since we already know the triangle was rendered by the rasterizer, we
    // mostly want to calculate at what distance it does
    if (!distance_from_triangle_plane(cameraRay, triangleWS, intersectionDistance))
    {
        imageStore(t_OutLitImage, screenPos, vec4(0));
        return;
    }

    ray cameraRayDDX;
    cameraRayDDX.origin = g_Camera.position;
    cameraRayDDX.direction = subgroupQuadSwapHorizontal(cameraRay.direction);

    float intersectionDistanceDDX;
    distance_from_triangle_plane(cameraRayDDX, triangleWS, intersectionDistanceDDX);

    ray cameraRayDDY;
    cameraRayDDY.origin = g_Camera.position;
    cameraRayDDY.direction = subgroupQuadSwapVertical(cameraRay.direction);

    // We do the same ray tracing with the nearby quads, so we can calculate UV gradients for our sampler
    float intersectionDistanceDDY;
    distance_from_triangle_plane(cameraRayDDX, triangleWS, intersectionDistanceDDY);

    const vec3 positionWS = ray_point_at(cameraRay, intersectionDistance);
    const vec3 positionDDX = ray_point_at(cameraRayDDX, intersectionDistanceDDX);
    const vec3 positionDDY = ray_point_at(cameraRayDDY, intersectionDistanceDDY);

    barycentric_coords bc;
    barycentric_calculate(bc, triangleWS.v, positionWS);

    barycentric_coords bcDDX;
    barycentric_calculate(bcDDX, triangleWS.v, positionDDX);

    barycentric_coords bcDDY;
    barycentric_calculate(bcDDX, triangleWS.v, positionDDY);

    // Interpolate attributes
    const vec3 normalWS = barycentric_interpolate(bc, triangleNormalWS);
    const vec2 uv0 = barycentric_interpolate(bc, triangleUV0);

    // Calculate the UV gradients as well
    const vec2 uv0QuadX = barycentric_interpolate(bcDDX, triangleUV0);
    const vec2 uv0QuadY = barycentric_interpolate(bcDDY, triangleUV0);

    const vec2 uv0DDX = uv0 - uv0QuadX;
    const vec2 uv0DDY = uv0 - uv0QuadY;

    // Finally sample the textures and do the lighting (WIP)
    const vec4 color = texture_sample_2d_grad(material.albedoTexture, OBLO_SAMPLER_LINEAR, uv0, uv0DDX, uv0DDY);

    vec3 reflected = vec3(0);

    for (uint lightIndex = 0; lightIndex < g_LightConfig.lightsCount; ++lightIndex)
    {
        reflected += light_contribution(lights[lightIndex], positionWS, normalWS);
    }

    const vec4 final = vec4(color.xyz * material.albedo * reflected, 1);

    imageStore(t_OutLitImage, screenPos, final);
}