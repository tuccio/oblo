#version 460

#extension GL_ARB_gpu_shader_int64 : require
#extension GL_EXT_buffer_reference : require
#extension GL_EXT_nonuniform_qualifier : require
#extension GL_EXT_shader_8bit_storage : require
#extension GL_EXT_samplerless_texture_functions : require
#extension GL_GOOGLE_include_directive : require
#extension GL_KHR_shader_subgroup_quad : require
#extension GL_EXT_control_flow_attributes : enable

#include <renderer/camera>
#include <renderer/constants>
#include <renderer/geometry/volumes>
#include <renderer/instances>
#include <renderer/lights>
#include <renderer/material>
#include <renderer/math>
#include <renderer/meshes/mesh_attributes>
#include <renderer/meshes/mesh_data>
#include <renderer/meshes/mesh_indices>
#include <renderer/meshes/mesh_table>
#include <renderer/shading/normal_mapping>
#include <renderer/shading/pbr>
#include <renderer/textures>
#include <renderer/transform>
#include <visibility/visibility_shading>

layout(binding = 0) uniform b_LightConfig
{
    light_config g_LightConfig;
};

layout(std430, binding = 1) restrict readonly buffer b_LightData
{
    light_data g_Lights[];
};

layout(std430, binding = 2) restrict readonly buffer b_ShadowMaps
{
    uint g_ShadowMaps[];
};

vec4 visibility_shade(in visibility_shade_context ctx)
{
    // Read the instance data we need
    const mesh_handle mesh = OBLO_INSTANCE_DATA(ctx.vb.instanceTableId, i_MeshHandles, ctx.vb.instanceId);
    const transform transform = OBLO_INSTANCE_DATA(ctx.vb.instanceTableId, i_TransformBuffer, ctx.vb.instanceId);
    const gpu_material material = OBLO_INSTANCE_DATA(ctx.vb.instanceTableId, i_MaterialBuffer, ctx.vb.instanceId);

    triangle triangleWS;
    vec2 triangleUV0[3];
    vec3 triangleNormal[3];
    vec3 triangleTangent[3];
    vec3 triangleBitangent[3];

    // Read the mesh data
    const mesh_table meshTable = mesh_table_fetch(mesh);
    const uvec3 vertexIndices = mesh_get_meshlet_indices(meshTable, mesh, ctx.vb.meshletId, ctx.vb.meshletTriangleId);

    // Read the vertex data and transform everything in world space, we do lighting calculation in that space
    [[unroll]] for (uint i = 0; i < 3; ++i)
    {
        const uint vertexId = vertexIndices[i];

        const vec3 vertexPosition = mesh_get_position(meshTable, vertexId);
        triangleWS.v[i] = (transform.localToWorld * vec4(vertexPosition, 1)).xyz;

        const vec3 vertexNormal = mesh_get_normal(meshTable, vertexId);
        triangleNormal[i] = vertexNormal;

        const vec3 vertexTangent = mesh_get_tangent(meshTable, vertexId);
        triangleTangent[i] = vertexTangent;

        const vec3 vertexBitangent = mesh_get_bitangent(meshTable, vertexId);
        triangleBitangent[i] = vertexBitangent;

        triangleUV0[i] = mesh_get_uv0(meshTable, vertexId);
    }

    barycentric_coords bc, bcDDX, bcDDY;
    vec3 positionWS;

    if (!calculate_position_and_barycentric_coords(ctx.screenPos,
            ctx.resolution,
            triangleWS,
            positionWS,
            bc,
            bcDDX,
            bcDDY))
    {
        return visibility_miss(ctx);
    }

    // Interpolate UV0 and calculate gradients
    const vec2 uv0 = barycentric_interpolate(bc, triangleUV0);

    vec2 uv0DDX, uv0DDY;
    barycentric_partial_derivatives(bcDDX, bcDDY, uv0, triangleUV0, uv0DDX, uv0DDY);

    vec3 normalWS;

    if (material.normalMapTexture != 0)
    {
        const vec4 sampledNormal =
            texture_sample_2d_grad(material.normalMapTexture, OBLO_SAMPLER_LINEAR, uv0, uv0DDX, uv0DDY);

        const vec3 T = normalize(barycentric_interpolate(bc, triangleTangent));
        const vec3 B = normalize(barycentric_interpolate(bc, triangleBitangent));
        const vec3 N = normalize(barycentric_interpolate(bc, triangleNormal));

        normalWS = normal_mapping(sampledNormal, T, B, N, mat3(transform.normalMatrix));
    }
    else
    {
        const vec3 N = barycentric_interpolate(bc, triangleNormal);
        normalWS = normalize(mat3(transform.normalMatrix) * N);
    }

    // Extract the PBR parameters from the material
    pbr_material pbr;
    pbr.albedo = material.albedo;
    pbr.metalness = material.metalness;
    pbr.roughness = material.roughness;
    pbr.ior = material.ior;

    if (material.albedoTexture != 0)
    {
        const vec3 albedo =
            texture_sample_2d_grad(material.albedoTexture, OBLO_SAMPLER_LINEAR, uv0, uv0DDX, uv0DDY).xyz;

        pbr.albedo *= albedo;
    }

    if (material.metalnessRoughnessTexture != 0)
    {
        const vec4 metalnessRoughness =
            texture_sample_2d_grad(material.metalnessRoughnessTexture, OBLO_SAMPLER_LINEAR, uv0, uv0DDX, uv0DDY);

        pbr.metalness *= metalnessRoughness.x;
        pbr.roughness *= metalnessRoughness.y;
    }

    vec3 reflected = vec3(0);
    const vec3 viewWS = normalize(g_Camera.position - positionWS);

    for (uint lightIndex = 0; lightIndex < g_LightConfig.lightsCount; ++lightIndex)
    {
        float visibility = 1.f;

        const uint visibilityMap = g_ShadowMaps[lightIndex];

        if (visibilityMap != 0)
        {
            visibility =
                texture_sample_2d(visibilityMap, OBLO_SAMPLER_NEAREST, (vec2(ctx.screenPos) + .5f) / ctx.resolution).r;
        }

        vec3 L;

        const vec3 contribution = light_contribution(g_Lights[lightIndex], positionWS, L);
        const vec3 brdf = pbr_brdf(normalWS, viewWS, L, pbr);

        reflected += visibility * contribution * brdf;
    }

    vec3 emitted = material.emissive;

    if (material.emissiveTexture != 0)
    {
        const vec3 emissive =
            texture_sample_2d_grad(material.emissiveTexture, OBLO_SAMPLER_LINEAR, uv0, uv0DDX, uv0DDY).xyz;

        emitted *= emissive;
    }

    const vec3 outLight = emitted + reflected;

    // A simple color mapping for now, since we have none implemented and we output to RGBA8
    return vec4(outLight / (outLight + 1), 1);
}

vec4 visibility_miss(in visibility_shade_context ctx)
{
    const vec2 ndc = screen_to_ndc(ctx.screenPos, ctx.resolution);
    const ray cameraRay = visibility_calculate_camera_ray(g_Camera, ndc);

    // Generate sphere UVs to sample the skybox
    vec2 uv;
    uv.x = 0.5f + atan(cameraRay.direction.z, cameraRay.direction.x) / (2 * float_pi());
    uv.y = 0.5f - asin(cameraRay.direction.y) / float_pi();

    const vec2 uvQuadX = subgroupQuadSwapHorizontal(uv);
    const vec2 uvQuadY = subgroupQuadSwapVertical(uv);

#if 0 // Using gradients this way introduces a seam where the skybox wraps, maybe we can just choose a mipmap manually instead
    const vec2 uvDDX = uv - uvQuadX;
    const vec2 uvDDY = uv - uvQuadY;

    const vec4 color = texture_sample_2d_grad(g_Constants.skybox, OBLO_SAMPLER_LINEAR, uv, uvDDX, uvDDY);

#else
    const uint lod = 0;
    const vec4 color = texture_sample_2d_lod(g_Constants.skybox, OBLO_SAMPLER_LINEAR, uv, 0);
#endif

    return color;
}
