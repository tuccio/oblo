#version 460

#extension GL_GOOGLE_include_directive : require
#extension GL_EXT_control_flow_attributes : enable
#extension GL_EXT_buffer_reference : require
#extension GL_EXT_shader_8bit_storage : require
#extension GL_ARB_gpu_shader_int64 : require

#include <renderer/camera>
#include <renderer/instances>
#include <renderer/math>
#include <renderer/meshes/mesh_attributes>
#include <renderer/meshes/mesh_data>
#include <renderer/meshes/mesh_indices>
#include <renderer/meshes/mesh_table>
#include <renderer/transform>
#include <visibility/visibility_buffer>
#include <visibility/visibility_utils>

layout(binding = 0, rgba16f) uniform restrict readonly image2D t_InSource;
layout(binding = 1, rgba16f) uniform restrict writeonly image2D t_OutFiltered;
layout(binding = 3, rg32ui) uniform restrict readonly uimage2D t_InVisibilityBuffer;

layout(binding = 16) uniform b_CameraBuffer
{
    camera_buffer g_Camera;
};

const uint g_PassIndex = GI_FILTER_PASS_INDEX;
const uint g_Stride = 1u << g_PassIndex;

// We run 8x8 groups
const uint g_ThreadLocalSize = 8;

// We only tap 3 pixels: the center, 1 at the left and 1 at the right, but each pass has different stride
const uint g_TapsPerPixel = 3;
const uint g_TapRadius = g_TapsPerPixel / 2;

const uint g_CacheSize = g_ThreadLocalSize + 2 * g_TapRadius * g_Stride;
const uint g_LoadsPerThread = (g_CacheSize + g_ThreadLocalSize - 1) / g_ThreadLocalSize;

shared vec3 g_IrradianceCache[g_CacheSize][g_CacheSize];
shared float g_DepthCache[g_CacheSize][g_CacheSize];
shared vec3 g_NormalCache[g_CacheSize][g_CacheSize];

ivec2 apply_offset_clamp(in ivec2 pixel, in uvec2 offset, in uvec2 resolution)
{
    return ivec2(min(int(resolution.x), int(pixel.x + offset.x)), min(int(resolution.y), int(pixel.y + offset.y)));
}

void load_shared_cache(in uvec2 resolution);

layout(local_size_x = g_ThreadLocalSize, local_size_y = g_ThreadLocalSize, local_size_z = 1) in;

void main()
{
    const uvec2 resolution = imageSize(t_InSource);

    load_shared_cache(resolution);

    memoryBarrierShared();
    barrier();

    const uvec2 screenPos = gl_GlobalInvocationID.xy;

    if (screenPos.x >= resolution.x || screenPos.y >= resolution.y)
    {
        return;
    }

    const uvec2 center = uvec2(g_Stride) + gl_LocalInvocationID.xy;

    vec3 result = vec3(0);

    const float kernel[g_TapsPerPixel] = {1.f, 2.f / 3.f, 1.f / 6.f};

    float weightSum = 0.f;

    const vec3 irradianceCenter = g_IrradianceCache[center.y][center.x];
    const float depthCenter = g_DepthCache[center.y][center.x];
    const vec3 normalCenter = g_NormalCache[center.y][center.x];

    const int k = int(g_TapRadius);

    [[unroll]] for (int y = -k; y <= k; ++y)
    {
        [[unroll]] for (int x = -k; x <= k; ++x)
        {
            const uvec2 coords = uvec2(center + ivec2(x, y) * g_Stride);
            const vec3 irradiance = g_IrradianceCache[coords.y][coords.x];
            const float depth = g_DepthCache[coords.y][coords.x];
            const vec3 normal = g_NormalCache[coords.y][coords.x];

            float w = kernel[abs(x)] * kernel[abs(y)];

            const float invDepthSigma = 1e2;
            w *= exp(-abs(depth - depthCenter) * invDepthSigma);
            w *= pow(saturate(dot(normal, normalCenter)), 32.f);

            result += w * irradiance;

            weightSum += w;
        }
    }

    if (weightSum > 1e-6)
    {
        result /= weightSum;
    }

    imageStore(t_OutFiltered, ivec2(screenPos), vec4(irradianceCenter, 1));
    // imageStore(t_OutFiltered, ivec2(screenPos), vec4(result, 1));
}

void sample_geometry(
    in visibility_buffer_data vb, in ivec2 coords, in uvec2 resolution, out float depth, out vec3 normalWS)
{
    const mesh_handle mesh = OBLO_INSTANCE_DATA(vb.instanceTableId, i_MeshHandles, vb.instanceId);
    const transform transform = OBLO_INSTANCE_DATA(vb.instanceTableId, i_TransformBuffer, vb.instanceId);

    // Read the mesh data
    const mesh_table meshTable = mesh_table_fetch(mesh);

    const uvec3 vertexIndices = mesh_get_meshlet_indices(meshTable, mesh, vb.meshletId, vb.meshletTriangleId);

    triangle triangleWS;
    vec3 triangleNormal[3];

    // Read the vertex data and transform everything in world space, we do lighting calculation in that
    // space
    [[unroll]] for (uint i = 0; i < 3; ++i)
    {
        const uint vertexId = vertexIndices[i];

        const vec3 vertexPosition = mesh_get_position(meshTable, vertexId);
        triangleWS.v[i] = (transform.localToWorld * vec4(vertexPosition, 1)).xyz;

        const vec3 vertexNormal = mesh_get_normal(meshTable, vertexId);
        triangleNormal[i] = vertexNormal;
    }

    const vec2 ndc = screen_to_ndc(uvec2(coords), resolution);

    const ray cameraRay = visibility_calculate_camera_ray(g_Camera, ndc);

    float intersectionDistance;

    distance_from_triangle_plane(cameraRay, triangleWS, intersectionDistance);

    const vec3 positionWS = ray_point_at(cameraRay, intersectionDistance);

    barycentric_coords bc;
    barycentric_calculate(bc, triangleWS.v, positionWS);

    depth = intersectionDistance;

    // Note that we are ignoring normal mapping here, which is probably an ok compromise
    const vec3 N = barycentric_interpolate(bc, triangleNormal);
    normalWS = normalize(mat3(transform.normalMatrix) * N);
}

void load_shared_cache(in uvec2 resolution)
{
    const uvec2 firstGroupPixel = gl_WorkGroupID.xy * gl_WorkGroupSize.xy;
    const ivec2 firstPixelToLoad = max(ivec2(0), ivec2(firstGroupPixel) - ivec2(g_Stride));

    [[unroll]] for (uint loadY = 0; loadY < g_LoadsPerThread; ++loadY)
    {
        [[unroll]] for (uint loadX = 0; loadX < g_LoadsPerThread; ++loadX)
        {
            const uvec2 offset = gl_WorkGroupSize.xy * uvec2(loadX, loadY) + gl_LocalInvocationID.xy;

            if (offset.x < g_CacheSize && offset.y < g_CacheSize)
            {
                const ivec2 coords = apply_offset_clamp(firstPixelToLoad, offset, resolution);
                const vec4 pixel = imageLoad(t_InSource, coords);

                g_IrradianceCache[offset.y][offset.x] = pixel.xyz;

                const uvec4 vbPixel = imageLoad(t_InVisibilityBuffer, coords);

                visibility_buffer_data vb;

                const bool isGeometrySample = visibility_buffer_parse(vbPixel.xy, vb);

                float depth;
                vec3 normalWS;

                if (visibility_buffer_parse(vbPixel.xy, vb))
                {
                    sample_geometry(vb, coords, resolution, depth, normalWS);
                }
                else
                {
                    // We use negative depth to signify no geometry (e.g. sky)
                    depth = -1.f;
                }

                g_DepthCache[offset.y][offset.x] = depth;
                g_NormalCache[offset.y][offset.x] = normalWS;
            }
        }
    }
}